---

### <a name="section-a"></a>1.  Project Overview
##### The goal of this project to build an automated service (web) to constantly update a prediction model with happenings in the marketplace so that, at every point in time, users can get semi-accurate prediction of the prices of proposed cars or advice them to make price adjustments for existing ones.

---

### <a name="section-b"></a>2.  Actions



1. Identified top US cities with most cars per square inch. 

2. For those cities, A total of 26,000 Records were scraped using Beautifulsoup and Selenium over the course of 48 Hours. 

3. Data was acquired from Carfax.com and UsedCars.com

4. Data was then cleaned and validated using Python Pandas library. EDA was performed on this data. 

5. Multiple Linear Regression models were created and tested using pipelines offered by libraries such as Sklearn and StatsModels.  

6. Shared the insights with the client. 


#### Tools Used: Sklearn, StatsModels, Scipy, Patsy Selenium, Beautiful Soup, Python, Pandas, Matplotlib and Seaborn.

---
### <a name="section-b2"></a>2.  EDA


